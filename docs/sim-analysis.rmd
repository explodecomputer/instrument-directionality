---
title: Analysis of version 3 simulations
author: Gibran Hemani
date: 15/06/2017
---

Approximately 200,000 simulations have been performed of x associating with y, simulating different samples for x and y phenotypes and extracting the relevant SNPs from each to make a 2-sample MR analysis. Simulations are performed with the following variables. The causal and reverse causal effects were estimated using Rucker, median and mode estimators

- Sample size of x and y
- Number of instruments for x
- Number of instruments for y
- Number of confounders
- Number of instruments per confounder
- Causal effect of x on y (sometimes 0)
- Causal effects of confounders on x and y
- Variance explained by x instruments on x
- Variance explained by y instruments on y
- Proportion of instruments exhibiting pleiotropy
- Variance explained by x instruments on y and vice versa
- Effect of directional pleiotropy

Instruments for each MR test were selected either by

- Oracle (true instruments only)
- Top hits (significant hits for the exposure)
- Steiger (significant hits for the exposure that have Rsq > outcome)

Then the following tests were performed

- Rucker + rucker JK
- Median
- Mode

## Analysis

```{r }
library(tidyverse)
load("../results/sim3.rdata")

estimates <- inner_join(estimates, param, by="id")
instrument_validity <- inner_join(instrument_validity, param, by="id")

# meth <- data_frame(Method=unique(res$Method))
# meth$root <- c(rep("Mean", 7), rep("Mode", 4), rep("Median", 3))
# res <- inner_join(res, meth, by="Method")

# resnull <- bind_rows(
# 	filter(res, hypothesis=="xy", eff_x.y == 0),
# 	filter(res, hypothesis=="yx")
# )

# resnull_s_d <- group_by(resnull, Method, strategy, hypothesis) %>%
# 	summarise(fdr = sum(P < 0.05)/n())
# levels(resnull_s_d$hypothesis) <- c("No causal effect", "Reverse cause")

# resnull_s <- group_by(resnull, Method, strategy) %>%
# 	summarise(fdr = sum(P < 0.05)/n())

# resxy <- filter(res, hypothesis == "xy", eff_x.y != 0)
# resxy$eff_bin <- cut(resxy$eff_x.y, 3)

# resxy_s <- group_by(resxy, Method, strategy, eff_bin) %>%
# 	summarise(tdr=sum(P < 0.05)/n(), bias=mean(Estimate - eff_x.y), n=n(), bias_se=sd(Estimate - eff_x.y)/sqrt(n))






# function to make main plots

simeval <- function(res)
{

	# res$Method <- paste0(res$Method, " - ", res$strategy)

	require(tidyverse)
	require(ggrepel)

	res$strategy <- paste(res$selection, as.numeric(res$steiger_filtered), as.numeric(res$outlier_filtered))

	# Organise data
	resnull <- bind_rows(
		filter(res, hypothesis=="x", eff_x.y == 0),
		filter(res, hypothesis=="y")
	)
	resnull_s_d <- group_by(resnull, method, strategy, hypothesis) %>%
		summarise(fdr = sum(pval < 0.05)/n())
	levels(resnull_s_d$hypothesis) <- c("No causal effect", "Reverse cause")

	resnull_s <- group_by(resnull, method, strategy) %>%
		summarise(fdr = sum(pval < 0.05)/n())

	resxy <- filter(res, hypothesis == "x", eff_x.y != 0)
	resxy$eff_bin <- cut(resxy$eff_x.y, 3)

	resxy_s <- group_by(resxy, method, strategy, eff_bin) %>%
		summarise(tdr=sum(pval < 0.05)/n(), bias=mean(b - eff_x.y), n=n(), bias_se=sd(b - eff_x.y)/sqrt(n))



	temp <- resxy %>%
		group_by(method, strategy) %>%
		summarise(power=sum(pval < 0.01)/n())
	# temp <- inner_join(temp, meth, by="Method")
	# temp$Method <- as.factor(temp$Method)
	# temp$Method <- factor(temp$Method, levels=as.character(meth$Method))

	p_power <- ggplot(temp, aes(y=power, x=method)) +
		geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
		theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
		scale_colour_brewer(type="qual") +
		labs(colour="Instrument\nselection")



	temp <- resnull_s
	# temp <- inner_join(temp, meth, by="Method")
	# temp$Method <- as.factor(temp$Method)
	# temp$Method <- factor(temp$Method, levels=as.character(meth$Method))

	p_fdr <- ggplot(temp, aes(y=fdr, x=method)) +
		geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
		theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
		scale_colour_brewer(type="qual") +
		labs(colour="Instrument\nselection")


	temp1 <- resxy %>%
		group_by(method, strategy) %>%
		summarise(power=sum(pval < 0.01)/n())
	# temp1 <- inner_join(temp1, meth, by="Method")
	# temp1$Method <- as.factor(temp1$Method)
	# temp1$Method <- factor(temp1$Method, levels=as.character(meth$Method))

	temp2 <- resnull_s
	# temp2 <- inner_join(temp2, meth, by="Method")
	# temp2$Method <- as.factor(temp2$Method)
	# temp2$Method <- factor(temp2$Method, levels=as.character(meth$Method))

	temp <- merge(temp1, temp2, by=c("method", "strategy"))
	temp$meth2 <- paste0(temp$method, " - ", temp$strategy)
	p_powerfdr <- ggplot(subset(temp, strategy != "o"), aes(x=power, y=fdr)) +
		geom_point(aes(colour=strategy), size=3) +
		geom_text_repel(aes(label=method)) +
		scale_colour_brewer(type="qual") +
		labs(x="Power (higher is better)", y="FDR (lower is better)", colour="Instrument\nselection")

	temp <- resxy %>%
		group_by(method, strategy) %>%
		summarise(bias=mean(b - eff_x.y), se=sd(b-eff_x.y))
	# temp <- inner_join(temp, meth, by="Method")
	# temp$Method <- as.factor(temp$Method)
	# temp$Method <- factor(temp$Method, levels=as.character(meth$Method))

	p_bias <- ggplot(temp, aes(y=bias, x=method)) +
		geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
		geom_errorbar(position=position_dodge(width=0.3), aes(ymin=bias-se, ymax=bias+se, colour=strategy), width=0) +
		theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
		scale_colour_brewer(type="qual") +
		labs(colour="Instrument\nselection")

	return(list(p_power=p_power, p_fdr=p_fdr, p_powerfdr=p_powerfdr, p_bias=p_bias))

}



a <- simeval(res)
a[[1]]
ggsave("../images/steiger_pow.pdf", width=6, height=3)
a[[2]]
ggsave("../images/steiger_fdr.pdf", width=6, height=3)
a[[3]]
a[[4]]
```


Is Steiger finding better instruments?

```{r }

validity <- instrument_validity
validity$strategy <- paste(validity$selection, validity$measure)


validity$n <- validity$nidx
validity$n[validity$hypothesis == "y"] <- validity$nidy[validity$hypothesis == "y"]
validity$type2 <- "valid"
validity$type2[validity$hypothesis == "x" & validity$type == "y"] <- "reverse"
validity$type2[validity$hypothesis == "y" & validity$type == "x"] <- "reverse"
validity$type2[validity$type == "u"] <- "confounder"



validity$nbin <- cut(validity$n, breaks=10, labels=FALSE)

validity_s <- group_by(validity, strategy, nbin) %>%
	summarise(
		n=sum(counts), 
		direct=sum(counts[type2=="valid"])/n,
		confounder=sum(counts[type2=="confounder"])/n,
		reverse=sum(counts[type2=="reverse"])/n
	)
validity_sl <- gather(validity_s, key=key, value=value, direct, confounder, reverse)
save(validity_sl, file="validity.rdata")

ggplot(filter(validity_sl, !grepl("^o", strategy)), aes(x=strategy, y=value)) +
geom_bar(stat="identity", position="dodge", aes(fill=key)) +
scale_fill_brewer(type='qual') +
labs(y="Proportion of instruments", fill="SNP association") +
geom_text(aes(y=value+0.04, label=round(value, 2), fill=key), position=position_dodge(width=0.9)) +
theme(axis.text.y=element_blank(), axis.ticks=element_blank())
ggsave("../images/steiger_validity.pdf", width=6, height=6)


validity_sl$nbin <- validity_sl$nbin * 50000

ggplot(filter(validity_sl, !grepl("^o", strategy)), aes(x=nbin, y=value)) +
geom_point(aes(colour=key)) +
geom_line(aes(colour=key)) +
facet_grid(. ~ strategy) +
scale_colour_brewer(type="qual") +
labs(x="Instrument discovery sample size", y="Proportion of instruments", colour="SNP\nassociation") +
theme(axis.text.x=element_text(angle=90, hjust=1, vjust=0.5))
ggsave("../images/steiger_validity_nbin.pdf", width=6, height=6)


```



How does each method perform in terms of finding true positives?

```{r }


a[[1]]

# ## ---- Power ----

# temp <- resxy %>%
# 	group_by(Method, strategy) %>%
# 	summarise(power=sum(P < 0.01)/n())
# temp <- inner_join(temp, meth, by="Method")
# temp$Method <- as.factor(temp$Method)
# temp$Method <- factor(temp$Method, levels=as.character(meth$Method))

# ggplot(temp, aes(y=power, x=Method)) +
# geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_colour_brewer(type="qual") +
# labs(colour="Instrument\nselection")


# ggplot(resxy_s, aes(x=eff_bin, y=tdr, group=strategy)) +
# geom_point(aes(colour=strategy)) +
# geom_line(aes(colour=strategy)) +
# facet_wrap(~ Method) +
# scale_colour_brewer(type="qual") +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5))


```


False discovery rates of each method

```{r }


a[[2]]

# temp <- resnull_s
# temp <- inner_join(temp, meth, by="Method")
# temp$Method <- as.factor(temp$Method)
# temp$Method <- factor(temp$Method, levels=as.character(meth$Method))

# ggplot(temp, aes(y=fdr, x=Method)) +
# geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_colour_brewer(type="qual") +
# labs(colour="Instrument\nselection")


# temp <- resnull_s
# temp <- inner_join(temp, meth, by="Method")
# temp <- temp[order(temp$fdr), ]
# temp$meth2 <- as.factor(paste0(temp$Method, " - ", temp$strategy))
# temp$meth2 <- factor(temp$meth2, levels=as.character(unique(temp$meth2)))

# ggplot(subset(temp, strategy != "oracle"), aes(x=meth2, y=fdr)) +
# geom_bar(stat="identity", position="dodge", aes(fill=root, alpha=strategy)) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_fill_brewer(type="qual") +
# geom_hline(yintercept=0.05, linetype="dotted")

```

FDR vs Power for each method

```{r }

a[[3]]

# library(ggrepel)

# temp1 <- resxy %>%
# 	group_by(Method, strategy) %>%
# 	summarise(power=sum(P < 0.01)/n())
# temp1 <- inner_join(temp1, meth, by="Method")
# temp1$Method <- as.factor(temp1$Method)
# temp1$Method <- factor(temp1$Method, levels=as.character(meth$Method))

# temp2 <- resnull_s
# temp2 <- inner_join(temp2, meth, by="Method")
# temp2$Method <- as.factor(temp2$Method)
# temp2$Method <- factor(temp2$Method, levels=as.character(meth$Method))

# temp <- merge(temp1, temp2, by=c("Method", "strategy"))
# temp$meth2 <- paste0(temp$Method, " - ", temp$strategy)
# ggplot(subset(temp, strategy != "oracle"), aes(x=power, y=fdr)) +
# geom_point(aes(colour=strategy), size=3) +
# geom_text_repel(aes(label=Method)) +
# scale_colour_brewer(type="qual") +
# labs(x="Power (higher is better)", y="FDR (lower is better)", colour="Instrument\nselection")

```

How biased is each method for simulations where there is a real causal effect?

```{r }

a[[4]]

# temp <- resxy %>%
# 	group_by(Method, strategy) %>%
# 	summarise(bias=mean(Estimate - eff_x.y), se=sd(Estimate-eff_x.y))
# temp <- inner_join(temp, meth, by="Method")
# temp$Method <- as.factor(temp$Method)
# temp$Method <- factor(temp$Method, levels=as.character(meth$Method))

# ggplot(temp, aes(y=bias, x=Method)) +
# geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
# geom_errorbar(position=position_dodge(width=0.3), aes(ymin=bias-se, ymax=bias+se, colour=strategy), width=0) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_colour_brewer(type="qual") +
# labs(colour="Instrument\nselection")


# ggplot(resxy_s, aes(x=eff_bin, y=bias, group=strategy)) +
# geom_point(aes(colour=strategy)) +
# geom_errorbar(aes(ymin=bias-bias_se*1.96, ymax=bias+bias_se*1.96, colour=strategy), width=0) +
# geom_line(aes(colour=strategy)) +
# facet_wrap(~ Method) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_colour_brewer(type="qual")

```



