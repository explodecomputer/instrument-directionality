---
title: Analysis of version 3 simulations
author: Gibran Hemani
date: 15/06/2017
---


```{r, echo=FALSE, message=FALSE, warning=FALSE}

suppressPackageStartupMessages({
	library(knitr)
	library(tidyverse)
	library(ggrepel)
	library(randomForest)
})
opts_chunk$set(cache=FALSE, echo=TRUE, message=FALSE, warning=FALSE)
set.seed(100)
source('../scripts/fun-analysis.r')
# load("../results/sim3.rdata")

```

Read in the summary set metrics to be used as predictors for the random forest

```{r}
load("../results/sim3/agg-info.rdata")
info$id <- paste0(info$id, info$hypothesis)
metrics <- subset(info, !steiger_filtered & !outlier_filtered & selection == "e", select=-c(id.exposure, id.outcome, selection, steiger_filtered, outlier_filtered, hypothesis))
```

Read in the estimates to serve as the outcomes to validate against predictors

```{r }

load("res.rdata")
res <- subset(res, selection == "e")
res$strategy[res$strategy == "e 0 0"] <- "Tophits"
res$strategy[res$strategy == "e 1 0"] <- "DF"
res$strategy[res$strategy == "e 0 1"] <- "HF"
res$strategy[res$strategy == "e 1 1"] <- "DF + HF"
res$optvec <- 0
res$optvec[res$hypothesis == "x" & res$eff_x.y != 0 & res$pval < 0.001] <- 1
res$optvec[res$hypothesis == "y" & res$pval > 0.05] <- 1
res$optvec[res$hypothesis == "x" & res$eff_x.y == 0 & res$pval > 0.05] <- 1

```

Setup data for RF


```{r}

methodlist <- unique(x$method)
names(methodlist) <- methodlist

x <- inner_join(
		res %>% {data_frame(optvec = .$optvec, method=paste0(.$method, " - ", .$strategy), id = paste0(.$id, .$hypothesis))}, 
		metrics, 
		by=c("id")
	) %>% 
	dplyr::select(-c(nsnp_removed))

```

Split data into training and testing

```{r}
ids <- unique(paste0(res$id, res$hypothesis))
index <- runif(length(ids)) > 0.333
train_ids <- ids[index]
test_ids <- ids[!index]

```

Train random forests

```{r}

# rf <- mclapply(methodlist, function(m) {
# 	y <- subset(x, method == m, select=-c(method)) %>%
# 		dplyr::filter(id %in% train_ids) %>%
# 		dplyr::select(-c(id))
# 	return(
# 		randomForest(
# 			y = as.factor(y$optvec), 
# 			x = subset(y, select=-c(optvec)), 
# 			sampsize=5000,
# 			ntree=100,
# 			do.trace=TRUE
# 		)
# 	}, mc.cores=22)

rf <- list()

for(m in methodlist)
{
	y <- subset(x, method == m, select=-c(method)) %>%
		dplyr::filter(id %in% train_ids) %>%
		dplyr::select(-c(id))
	rf[[m]] <- randomForest(
		y = as.factor(y$optvec), 
		x = subset(y, select=-c(optvec)), 
		sampsize=5000,
		ntree=100,
		do.trace=TRUE
	)
}


save(rf, file="rf.rdata")
```

Test random forests

```{r}

pred <- mclapply(methodlist, function(m) {
	y <- subset(x, method == m, select=-c(method)) %>%
		dplyr::filter(id %in% test_ids) %>%
		dplyr::select(-c(id))
	p <- predict(rf[[m]], subset(y, select=-c(optvec)), type="prob")[,2]
	return(
		data_frame(method=m,
			auc = pROC::auc(y$optvec, p)[1],
			rsq = cor(p, y$optvec)^2
		)
	)
	}, mc.cores=14) %>% bind_rows()

pred <- separate(pred, method, sep=" - ", c("method", "selection"))
ggplot(pred, aes(x=method, y=auc, colour=selection, group=selection)) +
geom_point() +
theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) +
scale_colour_brewer(type="qual")
```

Obtain mixture of experts

```{r}

temp <- subset(res, select=c(b, eff_x.y, method, strategy, hypothesis, id))
temp$method <- paste0(temp$method, " - ", temp$strategy)
temp$bias <- abs(temp$b - temp$eff_x.y)
temp <- subset(temp, select=-c(method, strategy, b, eff_x.y))
temp$id <- paste0(temp$id, temp$hypothesis)
temp <- subset(temp, select=-c(hypothesis))

met <- subset(metrics, id %in% test_ids, select=-c(nsnp_removed))
idlist <- met$id

d <- mclapply(methodlist, function(m) {
	predict(rf[[m]], met, type="prob")[,2]
}) %>% bind_cols

sel <- tibble(
	id=met$id,
	selmethod = methodlist[apply(d, 1, function(x) which.max(x))]
)

res$idh <- paste0(res$id, res$hypothesis)
res2 <- inner_join(res, sel, by=c("idh"="id"))

res3 <- res2 %>%
	filter(selmethod == paste(method, "-", strategy))
res3$method <- "MoE - RF"
res3$strategy <- "Mixed"
res3 <- bind_rows(res2, res3)

```

Compare against single experts. 

FDR:


```{r}
resnull <- 	bind_rows(
		filter(res3, hypothesis=="x", eff_x.y == 0),
		filter(res3, hypothesis=="y")
	)	
resnull_s_d <- group_by(resnull, method, strategy, hypothesis) %>%
	summarise(fdr = sum(pval < 0.05)/n())
levels(resnull_s_d$hypothesis) <- c("No causal effect", "Reverse cause")
resnull_s <- group_by(resnull, method, strategy) %>%
	summarise(fdr = sum(pval < 0.05)/n())
temp <- resnull_s
p_fdr <- ggplot(temp %>% filter(!grepl("^o", strategy)), aes(y=fdr, x=method)) +
	geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
	theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
	scale_colour_brewer(type="qual") +
	labs(colour="Instrument\nselection")
ggsave(p_fdr, file="plot.pdf")
```

Power:

```{r}
resxy <- filter(res3, hypothesis == "x", eff_x.y != 0)
resxy$eff_bin <- cut(resxy$eff_x.y, 3)
resxy_s <- group_by(resxy, method, strategy, eff_bin) %>%
	summarise(tdr=sum(pval < 0.05)/n(), bias=mean(b - eff_x.y), n=n(), bias_se=sd(b - eff_x.y)/sqrt(n))
temp <- resxy %>%
	group_by(method, strategy) %>%
	summarise(power=sum(pval < 0.01)/n())
p_power <- ggplot(temp %>% filter(!grepl("^o", strategy)), aes(y=power, x=method)) +
	geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
	theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
	scale_colour_brewer(type="qual") +
	labs(colour="Instrument\nselection")
ggsave(p_power, file="plot.pdf")
```

Power vs FDR:


```{r}
temp1 <- resxy %>%
	group_by(method, strategy) %>%
	summarise(power=sum(pval < 0.01)/n())
temp2 <- resnull_s
temp <- merge(temp1, temp2, by=c("method", "strategy"))
temp$meth2 <- paste0(temp$method, " - ", temp$strategy)
p_powerfdr <- ggplot(subset(temp, !grepl("^o", strategy)), aes(x=power, y=fdr)) +
	geom_point(aes(colour=strategy), size=3) +
	geom_text_repel(aes(label=method)) +
	scale_colour_brewer(type="qual") +
	labs(x="Power (higher is better)", y="FDR (lower is better)", colour="Instrument\nselection")
ggsave(p_powerfdr, file="plot.pdf")
```

Bias:

```{r}
temp <- resxy %>%
	group_by(method, strategy) %>%
	summarise(bias=mean(b - eff_x.y), se=sd(b-eff_x.y))
p_bias <- ggplot(temp %>% filter(!method %in% c("Steiger null", "Wald ratio"), !grepl("^o", strategy)), aes(y=bias, x=method)) +
	geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
	geom_errorbar(position=position_dodge(width=0.3), aes(ymin=bias-se, ymax=bias+se, colour=strategy), width=0) +
	theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
	scale_colour_brewer(type="qual") +
	labs(colour="Instrument\nselection")
ggsave(p_bias, file="plot.pdf")

```

AUC:

```{r}
library(multidplyr)
rocs <- res3 %>% filter(selection == "e") %>%
partition(method, strategy) %>%
cluster_library("pROC") %>%
cluster_library("dplyr") %>%
do({
        r <- pROC::roc(.$causal, abs(.$b/.$se), ci=TRUE)
        tibble(
                n=nrow(.),
                auc=r$auc[1],
                ci_lo=r$ci[1],
                ci_up=r$ci[3]
        )
})

p1 <- ggplot(rocs %>% as_data_frame(), aes(x=method, y=auc, group=strategy, colour=strategy)) +
geom_point(position=position_dodge(width=0.3)) +
geom_errorbar(width=0, position=position_dodge(width=0.3), aes(ymin=ci_lo, ymax=ci_up)) +
theme(axis.text.x=element_text(angle=90)) +
scale_colour_brewer(type="qual") +
labs(colour="Selection") +
theme(axis.text.x=element_text(hjust=1, vjust=0.5))
ggsave(p1, file="../images/rocs3.pdf")



```

