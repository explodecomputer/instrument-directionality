---
title: Analysis of version 3 simulations
author: Gibran Hemani
date: 15/06/2017
---


```{r, echo=FALSE, message=FALSE, warning=FALSE}

suppressPackageStartupMessages({
	library(knitr)
	library(pROC)
	library(tidyverse)
	library(ggrepel)
})
opts_chunk$set(cache=FALSE, echo=TRUE, message=FALSE, warning=FALSE)
```


```{r }

library(tidyverse)
source('../scripts/fun-analysis.r')
# load("../results/sim3.rdata")
load("res.rdata")
load("../results/sim3/agg-info.rdata")
```

```{r}

opt1 <- rep(0, nrow(res))
opt1[res$hypothesis == "xy" & res$eff_x.y != 0 & res$P < 0.001] <- 1
opt1[res$hypothesis == "yx" & res$P > 0.05] <- 1
opt1[res$hypothesis == "xy" & res$eff_x.y == 0 & res$P > 0.05] <- 1
table(opt1)


rf2 <- make_optim_dataset(opt1, res, metrics, 14)
pr2 <- test_predictor(rf2$rf, rf2$sp, res, metrics)

res_rf2 <- add_method(rf2$rf, rf2$sp, res, metrics)
eval_rf2 <- simeval(res_rf2)
eval_rf2[[4]]

save(rf2, res_rf2, pr2, eval_rf2, file="../results/rf2.rdata")


res_lda1 <- add_method(lda1$rf, lda1$sp, res, metrics)
eval_lda1 <- simeval(res_lda1)
eval_lda1[[4]]


opt2 <- as.factor(opt1)
lda1 <- make_optim_dataset2(opt2, res, metrics, 2)
prlda1 <- test_predictor(lda1$rf, lda1$sp, res, metrics)

save(lda1, eval_lda1, file="../results/lda1.rdata")

x <- lda1$rf
save(x, file="temp.rdata")







# Make new optim instead of bias - ratio of p(xy) / p(yx)

temp <- filter(as.data.frame(res), eff_x.y != 0, strategy != "oracle") %>%
	dplyr::select(Method, P, hypothesis, strategy, sim) %>%
	spread(key=hypothesis, value=P) %>%
	mutate(xy=-log10(xy), yx=-log10(yx)) %>%
	as_data_frame

temp$xy[is.infinite(temp$xy)] <- 300
temp$yx[is.infinite(temp$yx)] <- 300
temp$rat <- temp$xy / temp$yx

group_by(temp, Method, strategy) %>%
	summarise(rat=mean(xy / yx)) %>%
	as.data.frame()

temp2 <- group_by(temp, sim) %>%
	summarise(meth=paste0(Method, " - ", strategy)[which.max(rat)][1])
table(temp2$meth)



```



```{r}
library(tidyverse)
load("../results/simulate3-methods.rdata")
load("../results/simulate3.rdata")
load("../results/rf2.rdata")
res <- inner_join(res, param, by="sim")
res$method <- paste0(res$Method, " - ", res$strategy)
metrics <- metrics[! apply(metrics, 1, function(x) any(is.na(x))), ]




```







```{r}

# library(DBI)
# library(RSQLite)
# library(dbplyr)
# con <- DBI::dbConnect(RSQLite::SQLite(), "estimates.sqlite")

# copy_to(con, res, "res",
# 	temporary = FALSE, 
# 	indexes = list(
# 		"id", 
# 		"hypothesis", 
# 		"strategy",
# 		"method",
# 		"selection"
# 	)
# )


```


```{r}

# meth <- data_frame(Method=unique(res$Method))
# meth$root <- c(rep("Mean", 7), rep("Mode", 4), rep("Median", 3))
# res <- inner_join(res, meth, by="Method")

# resnull <- bind_rows(
# 	filter(res, hypothesis=="xy", eff_x.y == 0),
# 	filter(res, hypothesis=="yx")
# )

# resnull_s_d <- group_by(resnull, Method, strategy, hypothesis) %>%
# 	summarise(fdr = sum(P < 0.05)/n())
# levels(resnull_s_d$hypothesis) <- c("No causal effect", "Reverse cause")

# resnull_s <- group_by(resnull, Method, strategy) %>%
# 	summarise(fdr = sum(P < 0.05)/n())

# resxy <- filter(res, hypothesis == "xy", eff_x.y != 0)
# resxy$eff_bin <- cut(resxy$eff_x.y, 3)

# resxy_s <- group_by(resxy, Method, strategy, eff_bin) %>%
# 	summarise(tdr=sum(P < 0.05)/n(), bias=mean(Estimate - eff_x.y), n=n(), bias_se=sd(Estimate - eff_x.y)/sqrt(n))






# function to make main plots



a <- simeval(res)
a[[1]]
ggsave("../images/steiger_pow.pdf", width=6, height=3)
a[[2]]
ggsave("../images/steiger_fdr.pdf", width=6, height=3)
a[[3]]
a[[4]]
```





How does each method perform in terms of finding true positives?

```{r }


a[[1]]

# ## ---- Power ----

# temp <- resxy %>%
# 	group_by(Method, strategy) %>%
# 	summarise(power=sum(P < 0.01)/n())
# temp <- inner_join(temp, meth, by="Method")
# temp$Method <- as.factor(temp$Method)
# temp$Method <- factor(temp$Method, levels=as.character(meth$Method))

# ggplot(temp, aes(y=power, x=Method)) +
# geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_colour_brewer(type="qual") +
# labs(colour="Instrument\nselection")


# ggplot(resxy_s, aes(x=eff_bin, y=tdr, group=strategy)) +
# geom_point(aes(colour=strategy)) +
# geom_line(aes(colour=strategy)) +
# facet_wrap(~ Method) +
# scale_colour_brewer(type="qual") +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5))


```


False discovery rates of each method

```{r }


a[[2]]

# temp <- resnull_s
# temp <- inner_join(temp, meth, by="Method")
# temp$Method <- as.factor(temp$Method)
# temp$Method <- factor(temp$Method, levels=as.character(meth$Method))

# ggplot(temp, aes(y=fdr, x=Method)) +
# geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_colour_brewer(type="qual") +
# labs(colour="Instrument\nselection")


# temp <- resnull_s
# temp <- inner_join(temp, meth, by="Method")
# temp <- temp[order(temp$fdr), ]
# temp$meth2 <- as.factor(paste0(temp$Method, " - ", temp$strategy))
# temp$meth2 <- factor(temp$meth2, levels=as.character(unique(temp$meth2)))

# ggplot(subset(temp, strategy != "oracle"), aes(x=meth2, y=fdr)) +
# geom_bar(stat="identity", position="dodge", aes(fill=root, alpha=strategy)) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_fill_brewer(type="qual") +
# geom_hline(yintercept=0.05, linetype="dotted")

```

FDR vs Power for each method

```{r }

a[[3]]

# library(ggrepel)

# temp1 <- resxy %>%
# 	group_by(Method, strategy) %>%
# 	summarise(power=sum(P < 0.01)/n())
# temp1 <- inner_join(temp1, meth, by="Method")
# temp1$Method <- as.factor(temp1$Method)
# temp1$Method <- factor(temp1$Method, levels=as.character(meth$Method))

# temp2 <- resnull_s
# temp2 <- inner_join(temp2, meth, by="Method")
# temp2$Method <- as.factor(temp2$Method)
# temp2$Method <- factor(temp2$Method, levels=as.character(meth$Method))

# temp <- merge(temp1, temp2, by=c("Method", "strategy"))
# temp$meth2 <- paste0(temp$Method, " - ", temp$strategy)
# ggplot(subset(temp, strategy != "oracle"), aes(x=power, y=fdr)) +
# geom_point(aes(colour=strategy), size=3) +
# geom_text_repel(aes(label=Method)) +
# scale_colour_brewer(type="qual") +
# labs(x="Power (higher is better)", y="FDR (lower is better)", colour="Instrument\nselection")

```

How biased is each method for simulations where there is a real causal effect?

```{r }

a[[4]]

# temp <- resxy %>%
# 	group_by(Method, strategy) %>%
# 	summarise(bias=mean(Estimate - eff_x.y), se=sd(Estimate-eff_x.y))
# temp <- inner_join(temp, meth, by="Method")
# temp$Method <- as.factor(temp$Method)
# temp$Method <- factor(temp$Method, levels=as.character(meth$Method))

# ggplot(temp, aes(y=bias, x=Method)) +
# geom_point(position=position_dodge(width=0.3), aes(colour=strategy), size=3) +
# geom_errorbar(position=position_dodge(width=0.3), aes(ymin=bias-se, ymax=bias+se, colour=strategy), width=0) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_colour_brewer(type="qual") +
# labs(colour="Instrument\nselection")


# ggplot(resxy_s, aes(x=eff_bin, y=bias, group=strategy)) +
# geom_point(aes(colour=strategy)) +
# geom_errorbar(aes(ymin=bias-bias_se*1.96, ymax=bias+bias_se*1.96, colour=strategy), width=0) +
# geom_line(aes(colour=strategy)) +
# facet_wrap(~ Method) +
# theme(axis.text.x=element_text(angle=90, hjust=0.5, vjust=0.5)) +
# scale_colour_brewer(type="qual")

```



